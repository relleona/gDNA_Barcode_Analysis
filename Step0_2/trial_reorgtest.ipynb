{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os  # For file and directory operations\n",
    "import re  # For regular expressions\n",
    "import shutil  # For high-level file operations\n",
    "import csv  # For reading and writing CSV files\n",
    "import pandas as pd  # For handling Excel files\n",
    "import openpyxl  # Required for pandas to read Excel files\n",
    "from argparse import ArgumentParser  # For parsing command-line arguments\n",
    "import Reorganizationfunction as Rf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path= \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/rawData_YG\"\n",
    "output_path = \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments \"\n",
    "stagger_file_path= \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/StaggerFileAll.csv\"\n",
    "script_path= \"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['Sample', 'Path', 'Index2', 'Stagger_Length']\n",
      "Number of sample IDs read: 16\n",
      "First few sample IDs: ['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive', 'BC02-A-1uM-PLX']\n"
     ]
    }
   ],
   "source": [
    "with open(stagger_file_path, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    # Trim whitespace from fieldnames\n",
    "    reader.fieldnames = [field.strip() for field in reader.fieldnames]\n",
    "    print(f\"CSV columns: {reader.fieldnames}\")\n",
    "    \n",
    "    # Find the correct column name for \"Sample\" (case-insensitive)\n",
    "    sample_column = next(\n",
    "        (field for field in reader.fieldnames if field.lower() == 'sample'), None)\n",
    "    if sample_column is None:\n",
    "        raise ValueError(\n",
    "            f\"'Sample' column not found in {stagger_file_path}. Available columns: {', '.join(reader.fieldnames)}\")\n",
    "    \n",
    "    sample_ids = [row[sample_column] for row in reader]\n",
    "    print(f\"Number of sample IDs read: {len(sample_ids)}\")\n",
    "    print(f\"First few sample IDs: {sample_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_common_prefix(sample_ids):\n",
    "    if not sample_ids:\n",
    "        return \"\"\n",
    "    \n",
    "    # Start with the first sample ID as the prefix\n",
    "    prefix = sample_ids[0]\n",
    "    \n",
    "    for sample_id in sample_ids[1:]:\n",
    "        # Find the common part between the current prefix and the new sample ID\n",
    "        common = \"\"\n",
    "        for i, (c1, c2) in enumerate(zip(prefix, sample_id)):\n",
    "            if c1 != c2:\n",
    "                break\n",
    "            common += c1\n",
    "        \n",
    "        # Update the prefix to be the common part\n",
    "        prefix = common\n",
    "        \n",
    "        # If we've reduced the prefix to nothing, stop\n",
    "        if not prefix:\n",
    "            break\n",
    "    \n",
    "    # Remove any trailing non-alphanumeric characters\n",
    "    prefix = re.sub(r'[^a-zA-Z0-9]+$', '', prefix)\n",
    "    \n",
    "    return prefix\n",
    "\n",
    "\n",
    "def group_samples(sample_ids):\n",
    "    # Initialize dictionaries to store groups and reverse mapping\n",
    "    groups = defaultdict(list)\n",
    "    sample_to_group = {}\n",
    "    \n",
    "    # Find the common prefix among all sample IDs\n",
    "    common_prefix = find_common_prefix(sample_ids)\n",
    "    prefix_length = len(common_prefix)\n",
    "    \n",
    "    # If common prefix is very short, try to extend it\n",
    "    if prefix_length < 3:\n",
    "        pattern = re.compile(rf'^({re.escape(common_prefix)}[A-Za-z0-9-]+)')\n",
    "    else:\n",
    "        pattern = re.compile(rf'^({re.escape(common_prefix)}[A-Za-z0-9]*)')\n",
    "    \n",
    "    # Group each sample ID and create reverse mapping\n",
    "    for sample_id in sample_ids:\n",
    "        match = pattern.match(sample_id)\n",
    "        if match:\n",
    "            group = match.group(1)\n",
    "            groups[group].append(sample_id)\n",
    "            sample_to_group[sample_id] = group\n",
    "        else:\n",
    "            # Fallback: use the whole sample ID as its own group\n",
    "            groups[sample_id].append(sample_id)\n",
    "            sample_to_group[sample_id] = sample_id\n",
    "    \n",
    "    return groups, sample_to_group\n",
    "\n",
    "# Function to get sample name from filename\n",
    "def get_sample_name(filename, group_samples):\n",
    "    # filename is the name of the file we are trying to match to the samplenames/subfolder\n",
    "    # group_samples is the name of the samplenames/subfolder\n",
    "\n",
    "    # Return the first sample name that matches the filename\n",
    "    # Next returns the second argument, which is None if the first value is empty, or there is no match\n",
    "    return next((sample for sample in group_samples if sample in filename), None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 3\n",
      "Group BC01: ['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive']\n",
      "Group BC02: ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX']\n",
      "Group BC03: ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']\n",
      "dict_keys(['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive', 'BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX', 'BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive'])\n"
     ]
    }
   ],
   "source": [
    "# Group samples\n",
    "sample_groups,sample_to_group  = Rf.group_samples(sample_ids)\n",
    "print(f\"Number of groups: {len(sample_groups)}\")\n",
    "for group, samples in list(sample_groups.items())[:5]:\n",
    "    print(f\"Group {group}: {samples}\")\n",
    "\n",
    "\n",
    "print(sample_to_group.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fastq_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m root, _, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(input_path):\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Filter for FASTQ files\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     fastq_files \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.fastq.gz\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(fastq_files)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fastq_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize variables for file counting and matching\n",
    "file_count = 0\n",
    "match_count = 0\n",
    "main_folders = {}\n",
    "\n",
    "\n",
    "# Walk through the input directory\n",
    "for root, _, files in os.walk(input_path):\n",
    "    # Filter for FASTQ files\n",
    "    fastq_files = [f for f in files if f.endswith('.fastq.gz')]\n",
    "\n",
    "print(fastq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main function with inputs: /projects/b1042/GoyalLab/aleona/YG10Xbarcode/rawData_YG, /projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments , /projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/StaggerFileAll.csv, /projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis\n",
      "Number of groups: 3\n",
      "Group BC01: ['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive']\n",
      "Group BC02: ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX']\n",
      "Group BC03: ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m file_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     37\u001b[0m match_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 38\u001b[0m main_folders \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)  \u001b[39m# Use defaultdict instead of regular dict\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# Walk through the input directory\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m root, _, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(input_path):\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Filter for .fastq.gz files\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# Find if in that folder sets there are files of the format\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Main function to reorganize FASTQ files and create necessary CSV files.\"\"\"\n",
    "\n",
    "# Print starting message with input parameters\n",
    "print(f\"Starting main function with inputs: {input_path}, {output_path}, {stagger_file_path}, {script_path}\")\n",
    "\n",
    "## Open and read the StaggerFileAll.csv file\n",
    "with open(stagger_file_path, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    # Trim whitespace from fieldnames\n",
    "    reader.fieldnames = [field.strip() for field in reader.fieldnames]\n",
    "\n",
    "    # Find the correct column name for \"Sample\" (case-insensitive)\n",
    "    sample_column = next(\n",
    "        (field for field in reader.fieldnames if field.lower() == 'sample'), None)\n",
    "\n",
    "    # Raise an error if the 'Sample' column is not found\n",
    "    if sample_column is None:\n",
    "        raise ValueError(\n",
    "            f\"'Sample' column not found in {stagger_file_path}. Available columns: {', '.join(reader.fieldnames)}\")\n",
    "\n",
    "    # Extract sample IDs from the 'Sample' column\n",
    "    sample_ids = [row[sample_column] for row in reader]\n",
    "\n",
    "\n",
    "# Group the samples and get the reverse mapping function\n",
    "sample_groups, sample_to_group = Rf.group_samples(sample_ids)\n",
    "\n",
    "# Print the number of groups\n",
    "print(f\"Number of groups: {len(sample_groups)}\")\n",
    "\n",
    "# Print the first 5 groups and their samples\n",
    "for group, samples in list(sample_groups.items())[:5]:\n",
    "    print(f\"Group {group}: {samples}\")\n",
    "\n",
    "# Initialize variables for file counting and matching\n",
    "file_count = 0\n",
    "match_count = 0\n",
    "main_folders = defaultdict(list)  # Use defaultdict instead of regular dict\n",
    "\n",
    "\n",
    "# Walk through the input directory\n",
    "for root, _, files in os.walk(input_path):\n",
    "    # Filter for .fastq.gz files\n",
    "    # Find if in that folder sets there are files of the format\n",
    "    fastq_files = [f for f in files if f.endswith('.fastq.gz')]\n",
    "    \n",
    "    # Process each fastq file\n",
    "    for file in fastq_files:\n",
    "        # Get the full file path\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Find the matching sample and group\n",
    "        # sample_to_group.keys() is the subfolder under raw \n",
    "        # sample_to_group.values() is the mainfolder\n",
    "        sample_name = Rf.get_sample_name(file, sample_to_group.keys())\n",
    "        \n",
    "        # If a matching sample is found, process the file\n",
    "        if sample_name:\n",
    "            # Get the group for this sample\n",
    "            group = sample_to_group[sample_name]\n",
    "            \n",
    "            # Update counters\n",
    "            match_count += 1\n",
    "            \n",
    "            # Create main folder path and add to dictionary\n",
    "            main_folder_path = os.path.join(output_path, group)\n",
    "            main_folders[main_folder_path].append(sample_name)\n",
    "            \n",
    "            # Create new directory structure for the sample\n",
    "            sample_dir = os.path.join(main_folder_path, \"raw\", sample_name)\n",
    "            \n",
    "            # Create the sample directory\n",
    "            os.makedirs(sample_dir, exist_ok=True)\n",
    "            \n",
    "            # Set the destination path for the file\n",
    "            destination = os.path.join(sample_dir, file)\n",
    "            \n",
    "            # Copy the file to its new location\n",
    "            try:\n",
    "                shutil.copy2(file_path, destination)\n",
    "                print(f\"Copied {file_path} to {destination}\")\n",
    "                file_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file_path}: {e}\")\n",
    "        else:\n",
    "            # Print a message if no matching sample is found\n",
    "            print(f\"Could not determine sample for file: {file}\")\n",
    "\n",
    "# Print summary of processed files\n",
    "print(f\"Total files processed: {file_count}\")\n",
    "print(f\"Found {match_count} matching files\")\n",
    "print(f\"Processed {len(main_folders)} main folders\")\n",
    "\n",
    "# Define the source file path for the config template\n",
    "sourcefile = os.path.join(script_path, \"templateInputFullRun.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def modify_config(source_file, destination_file, new_path_experiment_folder, \n",
    "                  new_stagger_file, new_sample_array):\n",
    "    try:\n",
    "        # Check if the source file exists\n",
    "        if not os.path.exists(source_file):\n",
    "            raise FileNotFoundError(f\"Source file not found: {source_file}\")\n",
    "\n",
    "        # Read the content of the source file\n",
    "        with open(source_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        print(\"Content of the source file:\")\n",
    "        print(content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "        # Define the variables we want to change and their new values\n",
    "        variables_to_change = {\n",
    "            'pathExperimentFolder': new_path_experiment_folder,\n",
    "            'staggerFile': new_stagger_file,\n",
    "            'sampleArray': new_sample_array,\n",
    "            'sampleArrayStarcode': new_sample_array\n",
    "        }\n",
    "\n",
    "        # Function to replace a variable's value\n",
    "        def replace_variable(match):\n",
    "            var_name = match.group(1)\n",
    "            if var_name in variables_to_change:\n",
    "                new_value = variables_to_change[var_name]\n",
    "                if isinstance(new_value, list):\n",
    "                    return f\"{var_name} = {new_value}\"\n",
    "                else:\n",
    "                    return f\"{var_name} = '{new_value}'\"\n",
    "            return match.group(0)\n",
    "\n",
    "        # Use regex to find and replace variable assignments\n",
    "        new_content = re.sub(r'(\\w+)\\s*=\\s*[\"\\']?.*?[\"\\']?(?=\\n|\\Z)', replace_variable, content, flags=re.DOTALL)\n",
    "\n",
    "        print(\"Modified content:\")\n",
    "        print(new_content)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "        # Ensure the directory for the destination file exists\n",
    "        os.makedirs(os.path.dirname(destination_file), exist_ok=True)\n",
    "\n",
    "        # Write the updated content to the destination file\n",
    "        with open(destination_file, 'w') as file:\n",
    "            file.write(new_content)\n",
    "\n",
    "        print(f\"Configuration updated and saved to: {destination_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "sourcefile=\"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/templateInputFullRun.py\"\n",
    "destinationfile = \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01/templateInputFullRun.py\"\n",
    "main_folder_path = \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01\"\n",
    "staggerfilepath= \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01/StaggerFile.csv\"\n",
    "sample_id_list\n",
    "\n",
    "# In your main function or wherever you call modify_config:\n",
    "try:\n",
    "    modify_config(sourcefile, destinationfile, main_folder_path, staggerfilepath, sample_id_list)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create config file: {destinationfile}\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original content: 82 lines\n",
      "Did not find or change pathExperimentFolder\n",
      "Did not find or change staggerFile\n",
      "Changed sampleArray\n",
      "Changed sampleArrayStarcode\n",
      "import os\n",
      "import subprocess\n",
      "#This file contains all the modifiable variables in this analysis pipeline and no other files need to be modified for regular use. Running this file will call all the steps for the analysis. The file structure of the script must be retained to run this pipeline easily. The description for each parameters is in the documentation doc.\n",
      "\n",
      "parameters = {\n",
      "    \"pathScript\": \"path/to/folder/containing/this/file\",\n",
      "    \"pathExperimentFolder\": \"path/to/dataset\",\n",
      "\n",
      "    \"step1ExtractBarcode\": {\n",
      "        \"staggerFile\": \"path/to/stagger/file.csv\",\n",
      "        \"checkVector\": \"before\",\n",
      "        \"barcodeLength\": \"90\",\n",
      "        \"minPhred\": \"14\",\n",
      "        \"excludedReads\": \"False\", \n",
      "        \"asciioffset\": \"33\"\n",
      "    },\n",
      "\n",
      "    \"step2LvHistogramMultipleSamples\": {\n",
      "        \"sampleArray\": [\"S1\", \"S2\", \"S3\"], \n",
      "        \"lvHistogramFraction\": \"partial\",\n",
      "        \"lvHistogramLength\": \"40\"\n",
      "    },\n",
      "\n",
      "    \"pauseBeforeStep3\": False,\n",
      "\n",
      "    \"step3StarcodeLvHistogram\": {\n",
      "        \"combinedSample\": \"yes\",\n",
      "        \"lengthStarcode\": \"40\",\n",
      "        \"distanceStarcode\": \"8\",\n",
      "        \"threadsStarcode\": \"8\",\n",
      "        \"sampleArrayStarcode\": [\"S1\", \"S2\", \"S3\"]\n",
      "    }\n",
      "}\n",
      "#####################################################################################################################################\n",
      "#Nothing needs to be modified in the entire pipeline beyond this.\n",
      "#####################################################################################################################################\n",
      "\n",
      "\n",
      "pathScript = parameters['pathScript']\n",
      "pathExperiment = parameters['pathExperimentFolder']\n",
      "\n",
      "# Step 0\n",
      "pathStep0 = os.path.join(pathScript,\"Step0_SampleReorganisation\",\"Step0.py\")\n",
      "pathRawFiles = os.path.join(pathExperiment, \"raw\")\n",
      "commandStep0 = [\"python3\", pathStep0, pathScript, pathRawFiles]\n",
      "subprocess.run(commandStep0)\n",
      "\n",
      "#Step 1\n",
      "pathStep1 = os.path.join(pathScript,\"Step1_extractBarcode\",\"Step1.py\")\n",
      "pathStaggerFile = parameters['step1ExtractBarcode']['staggerFile']\n",
      "checkVector = parameters['step1ExtractBarcode'][\"checkVector\"]\n",
      "lengthBarcode = parameters['step1ExtractBarcode'][\"barcodeLength\"]\n",
      "minPhredScore = parameters['step1ExtractBarcode'][\"minPhred\"]\n",
      "excludedReads = parameters['step1ExtractBarcode'][\"excludedReads\"]\n",
      "asciioffset = parameters['step1ExtractBarcode'][\"asciioffset\"]\n",
      "commandStep1 = [\"python3\", pathStep1, pathScript, pathExperiment, pathStaggerFile, checkVector,lengthBarcode, minPhredScore, str(excludedReads), asciioffset]\n",
      "subprocess.call(commandStep1)\n",
      "\n",
      "# Step 2\n",
      "pathStep2 = os.path.join(pathScript,\"Step2_LVHistogram_MultipleSample\",\"Step2.py\")\n",
      "sampleArray = dict_values([['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive'], ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX'], ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']])\n",
      "sampleArray = dict_values([['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive'], ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX'], ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']])\n",
      "lvHistogramFraction = parameters[\"step2LvHistogramMultipleSamples\"][\"lvHistogramFraction\"]\n",
      "lvHistogramLength = parameters[\"step2LvHistogramMultipleSamples\"][\"lvHistogramLength\"]\n",
      "commandStep2 = [\"python3\", pathStep2, pathScript, pathExperiment, sampleArray, lvHistogramFraction, lvHistogramLength]\n",
      "subprocess.call(commandStep2)\n",
      "\n",
      "#Step 3\n",
      "if parameters[\"pauseBeforeStep3\"] == False:\n",
      "    pathStep3 = os.path.join(pathScript,\"Step3_Starcode\",\"Step3.py\")\n",
      "    combinedSample = parameters[\"step3StarcodeLvHistogram\"][\"combinedSample\"]\n",
      "    lengthStarcode = parameters[\"step3StarcodeLvHistogram\"][\"lengthStarcode\"]\n",
      "    distanceStarcode = parameters[\"step3StarcodeLvHistogram\"][\"distanceStarcode\"]\n",
      "    threadsStarcode = parameters[\"step3StarcodeLvHistogram\"][\"threadsStarcode\"]\n",
      "    sampleArrayStarcode = dict_values([['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive'], ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX'], ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']])\n",
      "    if  sampleArrayStarcode != \"Multiple_Samples\": \n",
      "        sampleArrayStarcode = dict_values([['BC01-1-1uM-PLX', 'BC01-2-1uM-PLX', 'BC01-1-Naive', 'BC01-2-Naive'], ['BC02-A-1uM-PLX', 'BC02-B-1uM-PLX', 'BC02-A-100nM-PLX-1', 'BC02-A-100nM-PLX-2', 'BC02-B-100nM-PLX'], ['BC03-1-1uM-PLX-1', 'BC03-1-1uM-PLX-2', 'BC03-4-1uM-PLX', 'BC03-2-100nM-PLX', 'BC03-3-100nM-PLX', 'BC03-4-100nM-PLX', 'BC03-Naive']])\n",
      "    commandStep3 = [\"python3\", pathStep3, pathScript,pathExperiment, combinedSample,lengthStarcode, distanceStarcode, threadsStarcode, sampleArrayStarcode]\n",
      "    subprocess.call(commandStep3)\n",
      "else:\n",
      "    print(\"Step 3 is paused for review of LV plots.\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sourcefile=\"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/templateInputFullRun.py\"\n",
    "new_path_experiment_folder = \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01/templateInputFullRun.py\"\n",
    "main_folder_path = \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01\"\n",
    "new_stagger_file= \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Experiments/BC01/StaggerFile.csv\"\n",
    "new_sample_array = sample_groups.values()\n",
    "\n",
    "source_file = \"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/templateInputFullRun.py\"\n",
    "\n",
    "\n",
    "with open(source_file, 'r') as current_file:\n",
    "    content = current_file.read()\n",
    "\n",
    "print(f\"Original content:\\n{content}\\n\")\n",
    "\n",
    "# Function to replace a variable assignment\n",
    "def replace_var(var_name, new_value):\n",
    "    pattern = f\"({var_name}\\\\s*=\\\\s*).*\"\n",
    "    replacement = f\"\\\\1{new_value}\"\n",
    "    print(f\"Attempting to replace {var_name}\")\n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(f\"Replacement: {replacement}\")\n",
    "    new_content, count = re.subn(pattern, replacement, content, flags=re.MULTILINE)\n",
    "    if count > 0:\n",
    "        print(f\"Changed {var_name}\")\n",
    "    else:\n",
    "        print(f\"Did not find or change {var_name}\")\n",
    "    print(f\"Content after attempted change:\\n{new_content}\\n\")\n",
    "    return new_content\n",
    "\n",
    "# Perform replacements\n",
    "content = replace_var('pathExperimentFolder', f'\"{new_path_experiment_folder}\"')\n",
    "content = replace_var('staggerFile', f'\"{new_stagger_file}\"')\n",
    "content = replace_var('sampleArray', str(new_sample_array))\n",
    "content = replace_var('sampleArrayStarcode', str(new_sample_array))\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dir = {\n",
    "    #Input and output directories \n",
    "    #Path to Step0_2\n",
    "    \"pathScript\": \"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/Step0_2\",\n",
    "    #The path to the downloaded FASTQ files\n",
    "    \"path\":\"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/SubiaBarcodeseq01-386089854/20230823_Goyal_Subia_Barcodeseq-688734047\",\n",
    "    #The path to sample sheet, if doesn't exist put \"NA\"\n",
    "    \"sample_sheet\":\"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/Experiment/SAUpdated_GoyalPool3_SampleSheet_Apr2023.xlsx\", #created or taken from ENSEMBLE/GENECODE \n",
    "    #The path to primer sheet, if doesn't need put \"NA\"\n",
    "    \"primers_sheet\": \"/projects/b1042/GoyalLab/aleona/gDNA_Barcode_Analysis/Experiment/20200811_10X_BCSeq_Primers.xlsx\",\n",
    "    # If stagger file all exists already without the need for Sample Sheet or Primers Sheet put the path, if not place it as \"NA\"\n",
    "    \"staggerfileall\": \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Exp2/StaggerFileAll.csv\", # Can be NA\n",
    "    #The path to Experiments folders\n",
    "    \"exp\": \"/projects/b1042/GoyalLab/aleona/YG10Xbarcode/Exp2\",\n",
    "    #Depth of subfolders within the Experiment folder above to run the job scripts for\n",
    "    \"depth\" : \"1\" #Default is 1 and usually its the same if the format is followed\n",
    "}\n",
    "staggerfileall = input_dir['staggerfileall']\n",
    "sample_sheet = input_dir['sample_sheet']\n",
    "primers_sheet = input_dir['primers_sheet']\n",
    "\n",
    "if staggerfileall == \"NA\": \n",
    "    print(\"yay\")\n",
    "elif sample_sheet == \"NA\" and primers_sheet == \"NA\": \n",
    "    print(\"nay\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Barcode_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
